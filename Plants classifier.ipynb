{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c752f857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3dd1c632",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "afee4210",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 20\n",
    "img_height, img_width = 224, 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "725a464f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"E:/Plants/training1\"\n",
    "validation_dir = \"E:/Plants/validation1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4b6171f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9850 images belonging to 6 classes.\n",
      "Found 1205 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, target_size=(img_height, img_width),\n",
    "                                                    batch_size=batch_size, class_mode='categorical')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(validation_dir, target_size=(img_height, img_width),\n",
    "                                                              batch_size=batch_size, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7bd11deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(img_height, img_width, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9b6fb663",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a183e215",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dfbcbea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(6, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9601d1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "50069417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "307/307 [==============================] - 513s 2s/step - loss: 1.6435 - accuracy: 0.3603 - val_loss: 1.3969 - val_accuracy: 0.4468\n",
      "Epoch 2/20\n",
      "307/307 [==============================] - 521s 2s/step - loss: 1.0496 - accuracy: 0.5970 - val_loss: 1.1466 - val_accuracy: 0.5845\n",
      "Epoch 3/20\n",
      "307/307 [==============================] - 2120s 7s/step - loss: 0.8200 - accuracy: 0.6776 - val_loss: 1.2850 - val_accuracy: 0.5118\n",
      "Epoch 4/20\n",
      "307/307 [==============================] - 514s 2s/step - loss: 0.6904 - accuracy: 0.7276 - val_loss: 1.5528 - val_accuracy: 0.5465\n",
      "Epoch 5/20\n",
      "307/307 [==============================] - 537s 2s/step - loss: 0.6117 - accuracy: 0.7597 - val_loss: 1.4627 - val_accuracy: 0.5676\n",
      "Epoch 6/20\n",
      "307/307 [==============================] - 570s 2s/step - loss: 0.5584 - accuracy: 0.7764 - val_loss: 1.4716 - val_accuracy: 0.6081\n",
      "Epoch 7/20\n",
      "307/307 [==============================] - 564s 2s/step - loss: 0.5120 - accuracy: 0.7959 - val_loss: 1.8715 - val_accuracy: 0.5861\n",
      "Epoch 8/20\n",
      "307/307 [==============================] - 564s 2s/step - loss: 0.4655 - accuracy: 0.8140 - val_loss: 2.1089 - val_accuracy: 0.6073\n",
      "Epoch 9/20\n",
      "307/307 [==============================] - 571s 2s/step - loss: 0.4582 - accuracy: 0.8173 - val_loss: 1.9569 - val_accuracy: 0.5938\n",
      "Epoch 10/20\n",
      "307/307 [==============================] - 561s 2s/step - loss: 0.4266 - accuracy: 0.8305 - val_loss: 2.0729 - val_accuracy: 0.6047\n",
      "Epoch 11/20\n",
      "307/307 [==============================] - 562s 2s/step - loss: 0.4056 - accuracy: 0.8373 - val_loss: 1.8742 - val_accuracy: 0.6233\n",
      "Epoch 12/20\n",
      "307/307 [==============================] - 564s 2s/step - loss: 0.3863 - accuracy: 0.8438 - val_loss: 1.7389 - val_accuracy: 0.6402\n",
      "Epoch 13/20\n",
      "307/307 [==============================] - 562s 2s/step - loss: 0.3738 - accuracy: 0.8473 - val_loss: 1.8412 - val_accuracy: 0.6073\n",
      "Epoch 14/20\n",
      "307/307 [==============================] - 560s 2s/step - loss: 0.3633 - accuracy: 0.8575 - val_loss: 2.1466 - val_accuracy: 0.6157\n",
      "Epoch 15/20\n",
      "307/307 [==============================] - 563s 2s/step - loss: 0.3399 - accuracy: 0.8611 - val_loss: 2.5257 - val_accuracy: 0.5870\n",
      "Epoch 16/20\n",
      "307/307 [==============================] - 563s 2s/step - loss: 0.3525 - accuracy: 0.8613 - val_loss: 2.0732 - val_accuracy: 0.6588\n",
      "Epoch 17/20\n",
      "307/307 [==============================] - 562s 2s/step - loss: 0.3239 - accuracy: 0.8759 - val_loss: 1.9943 - val_accuracy: 0.6368\n",
      "Epoch 18/20\n",
      "307/307 [==============================] - 564s 2s/step - loss: 0.3189 - accuracy: 0.8758 - val_loss: 1.6829 - val_accuracy: 0.6233\n",
      "Epoch 19/20\n",
      "307/307 [==============================] - 562s 2s/step - loss: 0.2929 - accuracy: 0.8833 - val_loss: 2.4554 - val_accuracy: 0.5938\n",
      "Epoch 20/20\n",
      "307/307 [==============================] - 570s 2s/step - loss: 0.2941 - accuracy: 0.8846 - val_loss: 2.4971 - val_accuracy: 0.6402\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator, steps_per_epoch=train_generator.n // batch_size, epochs=epochs,\n",
    "                    validation_data=validation_generator, validation_steps=validation_generator.n // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c9351dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 - 27s - loss: 2.4866 - accuracy: 0.6423 - 27s/epoch - 714ms/step\n",
      "Test accuracy: 0.6423236727714539\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(validation_generator, verbose=2)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "46958fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "99e24d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img(\"C:/Users/Mohammed Qadir/Downloads/Roystonea regia endemic.jpeg\", target_size=(img_height, img_width))\n",
    "x = img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = x / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fc652f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 109ms/step\n",
      "Predicted class is: endemic we have 20\n",
      "Predicted class label: 2\n"
     ]
    }
   ],
   "source": [
    "probs = model.predict(x)\n",
    "label = np.argmax(probs)\n",
    "classify={'critically_endangered':0,'endangered':1,'endemic we have 20':2,'near_threatened':3,'rare':4,'vulnerable':5}\n",
    "# Print the predicted class label\n",
    "def get_key(val):\n",
    "    for key, value in classify.items():\n",
    "        if val == value:\n",
    "            return key\n",
    " \n",
    "    return \"key doesn't exist\"\n",
    "\n",
    "print('Predicted class is:',get_key(label))\n",
    "print('Predicted class label:', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "224a7d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"E:/Plants/plantsclassifier.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7910765b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "for filename in os.listdir(\"E:/Plants/training/endemic\"):\n",
    "    try:\n",
    "        with Image.open(os.path.join(\"E:/Plants/training/endemic\", filename)) as im:\n",
    "            im.verify()\n",
    "    except Exception as e:\n",
    "        print(f\"File {filename} is corrupted or truncated. Exception: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656142fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
